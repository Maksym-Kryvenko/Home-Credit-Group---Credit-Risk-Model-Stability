{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Home Credit 2024"]},{"cell_type":"markdown","metadata":{},"source":["# Import all required dependencies"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T11:48:38.986527Z","iopub.status.busy":"2024-02-17T11:48:38.986210Z","iopub.status.idle":"2024-02-17T11:48:45.275278Z","shell.execute_reply":"2024-02-17T11:48:45.274493Z","shell.execute_reply.started":"2024-02-17T11:48:38.986503Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/dask/dataframe/_pyarrow_compat.py:23: UserWarning: You are using pyarrow version 11.0.0 which is known to be insecure. See https://www.cve.org/CVERecord?id=CVE-2023-47248 for further details. Please upgrade to pyarrow>=14.0.1 or install pyarrow-hotfix to patch your current version.\n","  warnings.warn(\n"]}],"source":["import os\n","import gc\n","from glob import glob\n","from pathlib import Path\n","from datetime import datetime\n","\n","import numpy as np\n","import pandas as pd\n","import polars as pl\n","\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","import warnings\n","#warnings.simplefilter(action='ignore', category=FutureWarning)\n","#pd.set_option('display.max_columns', None)\n","#pd.set_option('display.max_rows', 500)\n","\n","import joblib\n","\n","from sklearn.model_selection import StratifiedGroupKFold, cross_val_score\n","from sklearn.metrics import roc_auc_score\n","from sklearn.ensemble import VotingClassifier\n","from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n","\n","import optuna\n","\n","import lightgbm as lgb\n","#import xgboost as xgb\n","#from sklearn.linear_model import LogisticRegression\n","#from sklearn.svm import SVC, LinearSVC\n","#from sklearn.ensemble import RandomForestClassifier\n","#from sklearn.neighbors import KNeighborsClassifier\n","#from sklearn.naive_bayes import GaussianNB\n","#from sklearn.linear_model import Perceptron\n","#from sklearn.linear_model import SGDClassifier\n","#from sklearn.tree import DecisionTreeClassifier\n","#from sklearn.ensemble import GradientBoostingClassifier, HistGradientBoostingClassifier"]},{"cell_type":"markdown","metadata":{},"source":["# Load Data"]},{"cell_type":"markdown","metadata":{},"source":["Depth values:\n","\n","* depth=0 - These are static features directly tied to a specific *case_id*.\n","* depth=1 - Each *case_id* has an associated historical record, indexed by *num_group1*.\n","* depth=2 - Each *case_id* has an associated historical record, indexed by both *num_group1* and *num_group2*."]},{"cell_type":"markdown","metadata":{},"source":["## Configure input paths\n"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T11:48:45.277375Z","iopub.status.busy":"2024-02-17T11:48:45.277030Z","iopub.status.idle":"2024-02-17T11:48:45.282136Z","shell.execute_reply":"2024-02-17T11:48:45.281286Z","shell.execute_reply.started":"2024-02-17T11:48:45.277343Z"},"trusted":true},"outputs":[],"source":["class CFG:\n","    root_dir = Path(\"/kaggle/input/home-credit-credit-risk-model-stability/\")\n","    train_dir = Path(\"/kaggle/input/home-credit-credit-risk-model-stability/parquet_files/train\")\n","    test_dir = Path(\"/kaggle/input/home-credit-credit-risk-model-stability/parquet_files/test\")"]},{"cell_type":"markdown","metadata":{},"source":["## Load feature definitions"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T11:48:45.283580Z","iopub.status.busy":"2024-02-17T11:48:45.283301Z","iopub.status.idle":"2024-02-17T11:48:45.316455Z","shell.execute_reply":"2024-02-17T11:48:45.315605Z","shell.execute_reply.started":"2024-02-17T11:48:45.283551Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Variable</th>\n","      <th>Description</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>actualdpd_943P</td>\n","      <td>Days Past Due (DPD) of previous contract (actu...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>actualdpdtolerance_344P</td>\n","      <td>DPD of client with tolerance.</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>addres_district_368M</td>\n","      <td>District of the person's address.</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>addres_role_871L</td>\n","      <td>Role of person's address.</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>addres_zip_823M</td>\n","      <td>Zip code of the address.</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>460</th>\n","      <td>totinstallast1m_4525188A</td>\n","      <td>Total amount of monthly instalments paid in th...</td>\n","    </tr>\n","    <tr>\n","      <th>461</th>\n","      <td>twobodfilling_608L</td>\n","      <td>Type of application process.</td>\n","    </tr>\n","    <tr>\n","      <th>462</th>\n","      <td>type_25L</td>\n","      <td>Contact type of a person.</td>\n","    </tr>\n","    <tr>\n","      <th>463</th>\n","      <td>typesuite_864L</td>\n","      <td>Persons accompanying the client during the loa...</td>\n","    </tr>\n","    <tr>\n","      <th>464</th>\n","      <td>validfrom_1069D</td>\n","      <td>Date since the client has an active campaign.</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>465 rows Ã— 2 columns</p>\n","</div>"],"text/plain":["                     Variable  \\\n","0              actualdpd_943P   \n","1     actualdpdtolerance_344P   \n","2        addres_district_368M   \n","3            addres_role_871L   \n","4             addres_zip_823M   \n","..                        ...   \n","460  totinstallast1m_4525188A   \n","461        twobodfilling_608L   \n","462                  type_25L   \n","463            typesuite_864L   \n","464           validfrom_1069D   \n","\n","                                           Description  \n","0    Days Past Due (DPD) of previous contract (actu...  \n","1                        DPD of client with tolerance.  \n","2                    District of the person's address.  \n","3                            Role of person's address.  \n","4                             Zip code of the address.  \n","..                                                 ...  \n","460  Total amount of monthly instalments paid in th...  \n","461                       Type of application process.  \n","462                          Contact type of a person.  \n","463  Persons accompanying the client during the loa...  \n","464      Date since the client has an active campaign.  \n","\n","[465 rows x 2 columns]"]},"metadata":{},"output_type":"display_data"}],"source":["feature_definitions_df = pd.read_csv(CFG.root_dir / \"feature_definitions.csv\")\n","display(feature_definitions_df)\n","pd.reset_option(\"display.max_rows\", 0)"]},{"cell_type":"markdown","metadata":{},"source":["## Data Collection and Preprocessing using Pipeline"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T11:48:45.318754Z","iopub.status.busy":"2024-02-17T11:48:45.318466Z","iopub.status.idle":"2024-02-17T11:48:45.331605Z","shell.execute_reply":"2024-02-17T11:48:45.330782Z","shell.execute_reply.started":"2024-02-17T11:48:45.318730Z"},"trusted":true},"outputs":[],"source":["class Pipeline:\n","    @staticmethod\n","    def set_table_dtypes(df):\n","        for col in df.columns:\n","            if col in [\"case_id\", \"WEEK_NUM\", \"num_group1\", \"num_group2\"]:\n","                df = df.with_columns(pl.col(col).cast(pl.Int64))\n","            elif col in [\"date_decision\"]:\n","                df = df.with_columns(pl.col(col).cast(pl.Date))\n","            elif col[-1] in (\"P\", \"A\"):\n","                df = df.with_columns(pl.col(col).cast(pl.Float64))\n","            elif col[-1] in (\"M\",):\n","                df = df.with_columns(pl.col(col).cast(pl.String))\n","            elif col[-1] in (\"D\",):\n","                df = df.with_columns(pl.col(col).cast(pl.Date))            \n","\n","        return df\n","    \n","    @staticmethod\n","    def handle_dates(df):\n","        for col in df.columns:\n","            if col[-1] in (\"D\",):\n","                df = df.with_columns(pl.col(col) - pl.col(\"date_decision\"))\n","                df = df.with_columns(pl.col(col).dt.total_days())\n","                \n","        df = df.drop(\"date_decision\", \"MONTH\")\n","\n","        return df\n","    \n","    @staticmethod\n","    def filter_cols(df):\n","        for col in df.columns:\n","            if col not in [\"target\", \"case_id\", \"WEEK_NUM\"]:\n","                isnull = df[col].is_null().mean()\n","\n","                if isnull > 0.95:\n","                    df = df.drop(col)\n","\n","        for col in df.columns:\n","            if (col not in [\"target\", \"case_id\", \"WEEK_NUM\"]) & (df[col].dtype == pl.String):\n","                freq = df[col].n_unique()\n","\n","                if (freq == 1) | (freq > 200):\n","                    df = df.drop(col)\n","\n","        return df"]},{"cell_type":"markdown","metadata":{},"source":["## Aggregate data from different datasets"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T11:48:45.333642Z","iopub.status.busy":"2024-02-17T11:48:45.332892Z","iopub.status.idle":"2024-02-17T11:48:45.349086Z","shell.execute_reply":"2024-02-17T11:48:45.348346Z","shell.execute_reply.started":"2024-02-17T11:48:45.333611Z"},"trusted":true},"outputs":[],"source":["class Aggregator:\n","    num_aggregators = [pl.max, pl.min, pl.first, pl.last, pl.mean]\n","    str_aggregators = [pl.max, pl.min, pl.first, pl.last] # n_unique\n","    group_aggregators = [pl.max, pl.min, pl.first, pl.last]\n","    \n","    @staticmethod\n","    def num_expr(df):\n","        cols = [col for col in df.columns if col[-1] in (\"P\", \"A\")]\n","        expr_all = []\n","        for method in Aggregator.num_aggregators:\n","            expr = [method(col).alias(f\"{method.__name__}_{col}\") for col in cols]\n","            expr_all += expr\n","\n","        return expr_all\n","\n","    @staticmethod\n","    def date_expr(df):\n","        cols = [col for col in df.columns if col[-1] in (\"D\",)]\n","        expr_all = []\n","        for method in Aggregator.num_aggregators:\n","            expr = [method(col).alias(f\"{method.__name__}_{col}\") for col in cols]  \n","            expr_all += expr\n","\n","        return expr_all\n","\n","    @staticmethod\n","    def str_expr(df):\n","        cols = [col for col in df.columns if col[-1] in (\"M\",)]\n","        \n","        expr_all = []\n","        for method in Aggregator.str_aggregators:\n","            expr = [method(col).alias(f\"{method.__name__}_{col}\") for col in cols]  \n","            expr_all += expr\n","            \n","        expr_mode = [\n","            pl.col(col)\n","            .drop_nulls()\n","            .mode()\n","            .first()\n","            .alias(f\"mode_{col}\")\n","            for col in cols\n","        ]\n","\n","        return expr_all + expr_mode\n","\n","    @staticmethod\n","    def other_expr(df):\n","        cols = [col for col in df.columns if col[-1] in (\"T\", \"L\")]\n","        \n","        expr_all = []\n","        for method in Aggregator.str_aggregators:\n","            expr = [method(col).alias(f\"{method.__name__}_{col}\") for col in cols]  \n","            expr_all += expr\n","\n","        return expr_all\n","    \n","    @staticmethod\n","    def count_expr(df):\n","        cols = [col for col in df.columns if \"num_group\" in col]\n","\n","        expr_all = []\n","        for method in Aggregator.group_aggregators:\n","            expr = [method(col).alias(f\"{method.__name__}_{col}\") for col in cols]  \n","            expr_all += expr\n","            \n","#         if len(cols) > 0:\n","#             method = pl.count\n","#             expr = [method(col).alias(f\"{method.__name__}_{col}\") for col in [cols[0]]]\n","#             expr_all += expr\n","\n","        return expr_all\n","\n","    @staticmethod\n","    def get_exprs(df):\n","        exprs = Aggregator.num_expr(df) + \\\n","                Aggregator.date_expr(df) + \\\n","                Aggregator.str_expr(df) + \\\n","                Aggregator.other_expr(df) + \\\n","                Aggregator.count_expr(df)\n","\n","        return exprs"]},{"cell_type":"markdown","metadata":{},"source":["## Read files with previous function application"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T11:48:45.351119Z","iopub.status.busy":"2024-02-17T11:48:45.350196Z","iopub.status.idle":"2024-02-17T11:48:45.362943Z","shell.execute_reply":"2024-02-17T11:48:45.362123Z","shell.execute_reply.started":"2024-02-17T11:48:45.351087Z"},"trusted":true},"outputs":[],"source":["def read_file(path, depth=None):\n","    df = pl.read_parquet(path)\n","    df = df.pipe(Pipeline.set_table_dtypes)\n","    \n","    if depth in [1, 2]:\n","        df = df.group_by(\"case_id\").agg(Aggregator.get_exprs(df))\n","    \n","    return df\n","\n","def read_files(regex_path, depth=None):\n","    chunks = []\n","    for path in glob(str(regex_path)):\n","        chunks.append(pl.read_parquet(path).pipe(Pipeline.set_table_dtypes))\n","        \n","    df = pl.concat(chunks, how=\"vertical_relaxed\")\n","    if depth in [1, 2]:\n","        df = df.group_by(\"case_id\").agg(Aggregator.get_exprs(df))\n","    \n","    return df"]},{"cell_type":"markdown","metadata":{},"source":["## Feature Engineering"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T11:48:45.364684Z","iopub.status.busy":"2024-02-17T11:48:45.364037Z","iopub.status.idle":"2024-02-17T11:48:45.371650Z","shell.execute_reply":"2024-02-17T11:48:45.370720Z","shell.execute_reply.started":"2024-02-17T11:48:45.364655Z"},"trusted":true},"outputs":[],"source":["def feature_eng(df_base, depth_0, depth_1, depth_2):\n","    df_base = (\n","        df_base\n","        .with_columns(\n","            month_decision = pl.col(\"date_decision\").dt.month(),\n","            weekday_decision = pl.col(\"date_decision\").dt.weekday(),\n","        )\n","    )\n","        \n","    for i, df in enumerate(depth_0 + depth_1 + depth_2):\n","        df_base = df_base.join(df, how=\"left\", on=\"case_id\", suffix=f\"_{i}\")\n","        \n","    df_base = df_base.pipe(Pipeline.handle_dates)\n","    \n","    return df_base"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T11:48:45.373039Z","iopub.status.busy":"2024-02-17T11:48:45.372734Z","iopub.status.idle":"2024-02-17T11:48:45.380808Z","shell.execute_reply":"2024-02-17T11:48:45.379992Z","shell.execute_reply.started":"2024-02-17T11:48:45.373016Z"},"trusted":true},"outputs":[],"source":["def to_pandas(df_data, cat_cols=None):\n","    df_data = df_data.to_pandas()\n","    \n","    if cat_cols is None:\n","        cat_cols = list(df_data.select_dtypes(\"object\").columns)\n","    \n","    df_data[cat_cols] = df_data[cat_cols].astype(\"category\")\n","    \n","    return df_data"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T11:48:45.382232Z","iopub.status.busy":"2024-02-17T11:48:45.381976Z","iopub.status.idle":"2024-02-17T11:48:45.395468Z","shell.execute_reply":"2024-02-17T11:48:45.394702Z","shell.execute_reply.started":"2024-02-17T11:48:45.382210Z"},"trusted":true},"outputs":[],"source":["def reduce_mem_usage(df, float16_as32=True):\n","    \"\"\" iterate through all the columns of a dataframe and modify the data type\n","        to reduce memory usage.        \n","    \"\"\"\n","    start_mem = df.memory_usage().sum() / 1024**2\n","    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n","    \n","    for col in df.columns:\n","        col_type = df[col].dtype\n","        if str(col_type)==\"category\":\n","            continue\n","        \n","        if col_type != object:\n","            c_min = df[col].min()\n","            c_max = df[col].max()\n","            if str(col_type)[:3] == 'int':\n","                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n","                    df[col] = df[col].astype(np.int8)\n","                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n","                    df[col] = df[col].astype(np.int16)\n","                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n","                    df[col] = df[col].astype(np.int32)\n","                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n","                    df[col] = df[col].astype(np.int64)  \n","            else:\n","                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n","                    if float16_as32:\n","                        df[col] = df[col].astype(np.float32)\n","                    else:\n","                        df[col] = df[col].astype(np.float16)                    \n","                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n","                    df[col] = df[col].astype(np.float32)\n","                else:\n","                    df[col] = df[col].astype(np.float64)\n","        else:\n","            df[col] = df[col].astype('category')\n","    end_mem = df.memory_usage().sum() / 1024**2\n","    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n","    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n","    \n","    return df"]},{"cell_type":"markdown","metadata":{},"source":["## Prepare Dataframe"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T11:48:45.398337Z","iopub.status.busy":"2024-02-17T11:48:45.398073Z","iopub.status.idle":"2024-02-17T11:48:45.409155Z","shell.execute_reply":"2024-02-17T11:48:45.408420Z","shell.execute_reply.started":"2024-02-17T11:48:45.398308Z"},"trusted":true},"outputs":[],"source":["def prepare_df(data_dir, cat_cols=None, mode=\"train\", display_store=False, train_cols=[]):\n","    print(\"Collecting data...\")\n","    data_store = {\n","        \"df_base\": read_file(data_dir / f\"{mode}_base.parquet\"),\n","        \"depth_0\": [\n","            read_file(data_dir / f\"{mode}_static_cb_0.parquet\"),\n","            read_files(data_dir / f\"{mode}_static_0_*.parquet\"),\n","        ],\n","        \"depth_1\": [\n","            read_files(data_dir / f\"{mode}_applprev_1_*.parquet\", 1),\n","            read_file(data_dir / f\"{mode}_tax_registry_a_1.parquet\", 1),\n","            read_file(data_dir / f\"{mode}_tax_registry_b_1.parquet\", 1),\n","            read_file(data_dir / f\"{mode}_tax_registry_c_1.parquet\", 1),\n","            read_file(data_dir / f\"{mode}_credit_bureau_b_1.parquet\", 1),\n","            read_file(data_dir / f\"{mode}_other_1.parquet\", 1),\n","            read_file(data_dir / f\"{mode}_person_1.parquet\", 1),\n","            read_file(data_dir / f\"{mode}_deposit_1.parquet\", 1),\n","            read_file(data_dir / f\"{mode}_debitcard_1.parquet\", 1),\n","        ],\n","        \"depth_2\": [\n","            read_file(data_dir / f\"{mode}_credit_bureau_b_2.parquet\", 2),\n","        ]\n","    }\n","    if display_store:\n","        display(data_store)\n","    \n","    print(\"Feature engeneering...\")\n","    feats_df = feature_eng(**data_store)\n","    print(\"  feats_df shape:\\t\", feats_df.shape)\n","    \n","    del data_store\n","    gc.collect()\n","    \n","    print(\"Filter cols...\")\n","    if mode == \"train\":\n","        feats_df = feats_df.pipe(Pipeline.filter_cols)\n","    else:\n","        train_cols = feats_df.columns if len(train_cols) == 0 else train_cols\n","        feats_df = feats_df.select([col for col in train_cols if col != \"target\"])\n","    print(\"  feats_df shape:\\t\", feats_df.shape)\n","    \n","    print(\"Convert to pandas...\")\n","    feats_df = to_pandas(feats_df, cat_cols)\n","    return feats_df"]},{"cell_type":"markdown","metadata":{},"source":["### Configure train data"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T11:48:45.410220Z","iopub.status.busy":"2024-02-17T11:48:45.409997Z","iopub.status.idle":"2024-02-17T11:51:04.886339Z","shell.execute_reply":"2024-02-17T11:51:04.885507Z","shell.execute_reply.started":"2024-02-17T11:48:45.410200Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting data...\n","Feature engeneering...\n","  feats_df shape:\t (1526659, 927)\n","Filter cols...\n","  feats_df shape:\t (1526659, 516)\n","Convert to pandas...\n"]}],"source":["train_df = prepare_df(CFG.train_dir)\n","cat_cols = list(train_df.select_dtypes(\"category\").columns)"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T11:51:04.887807Z","iopub.status.busy":"2024-02-17T11:51:04.887497Z","iopub.status.idle":"2024-02-17T11:51:04.892044Z","shell.execute_reply":"2024-02-17T11:51:04.891067Z","shell.execute_reply.started":"2024-02-17T11:51:04.887774Z"},"trusted":true},"outputs":[],"source":["#display(train_df)"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T11:51:04.893859Z","iopub.status.busy":"2024-02-17T11:51:04.893229Z","iopub.status.idle":"2024-02-17T11:51:04.901264Z","shell.execute_reply":"2024-02-17T11:51:04.900527Z","shell.execute_reply.started":"2024-02-17T11:51:04.893828Z"},"trusted":true},"outputs":[],"source":["#display(cat_cols)"]},{"cell_type":"markdown","metadata":{},"source":["### Configure test data"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T11:51:04.902678Z","iopub.status.busy":"2024-02-17T11:51:04.902350Z","iopub.status.idle":"2024-02-17T11:51:05.403256Z","shell.execute_reply":"2024-02-17T11:51:05.402352Z","shell.execute_reply.started":"2024-02-17T11:51:04.902656Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting data...\n","Feature engeneering...\n","  feats_df shape:\t (10, 926)\n","Filter cols...\n","  feats_df shape:\t (10, 515)\n","Convert to pandas...\n"]}],"source":["test_df = prepare_df(CFG.test_dir, cat_cols=cat_cols, mode=\"test\", train_cols=train_df.columns)"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T11:51:05.404817Z","iopub.status.busy":"2024-02-17T11:51:05.404437Z","iopub.status.idle":"2024-02-17T11:51:05.409037Z","shell.execute_reply":"2024-02-17T11:51:05.408040Z","shell.execute_reply.started":"2024-02-17T11:51:05.404783Z"},"trusted":true},"outputs":[],"source":["#display(test_df)"]},{"cell_type":"markdown","metadata":{},"source":["### Reduce memory usage and save"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T11:51:05.410364Z","iopub.status.busy":"2024-02-17T11:51:05.410111Z","iopub.status.idle":"2024-02-17T11:51:12.175436Z","shell.execute_reply":"2024-02-17T11:51:12.174579Z","shell.execute_reply.started":"2024-02-17T11:51:05.410342Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Memory usage of dataframe is 4574.60 MB\n","Memory usage after optimization is: 2357.21 MB\n","Decreased by 48.5%\n","Memory usage of dataframe is 0.05 MB\n","Memory usage after optimization is: 0.04 MB\n","Decreased by 15.4%\n"]}],"source":["train_df = reduce_mem_usage(train_df)\n","test_df = reduce_mem_usage(test_df)"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T11:51:12.179136Z","iopub.status.busy":"2024-02-17T11:51:12.178847Z","iopub.status.idle":"2024-02-17T11:51:12.184654Z","shell.execute_reply":"2024-02-17T11:51:12.183967Z","shell.execute_reply.started":"2024-02-17T11:51:12.179112Z"},"trusted":true},"outputs":[],"source":["#train_df.to_parquet(\"train_full.parquet\")"]},{"cell_type":"markdown","metadata":{},"source":["# Exploration"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T11:51:12.186143Z","iopub.status.busy":"2024-02-17T11:51:12.185819Z","iopub.status.idle":"2024-02-17T11:51:12.195811Z","shell.execute_reply":"2024-02-17T11:51:12.194988Z","shell.execute_reply.started":"2024-02-17T11:51:12.186113Z"},"trusted":true},"outputs":[{"data":{"text/plain":["'\\nprint(\"Train is duplicated:\\t\", train_df[\"case_id\"].duplicated().any())\\nprint(\"Train Week Range:\\t\", (train_df[\"WEEK_NUM\"].min(), train_df[\"WEEK_NUM\"].max()))\\n\\nprint()\\n\\nprint(\"Test is duplicated:\\t\", test_df[\"case_id\"].duplicated().any())\\nprint(\"Test Week Range:\\t\", (test_df[\"WEEK_NUM\"].min(), test_df[\"WEEK_NUM\"].max()))\\n'"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["print(\"Train is duplicated:\\t\", train_df[\"case_id\"].duplicated().any())\n","print(\"Train Week Range:\\t\", (train_df[\"WEEK_NUM\"].min(), train_df[\"WEEK_NUM\"].max()))\n","\n","print()\n","\n","print(\"Test is duplicated:\\t\", test_df[\"case_id\"].duplicated().any())\n","print(\"Test Week Range:\\t\", (test_df[\"WEEK_NUM\"].min(), test_df[\"WEEK_NUM\"].max()))\n"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T11:51:12.197246Z","iopub.status.busy":"2024-02-17T11:51:12.196927Z","iopub.status.idle":"2024-02-17T11:51:12.205885Z","shell.execute_reply":"2024-02-17T11:51:12.204975Z","shell.execute_reply.started":"2024-02-17T11:51:12.197216Z"},"trusted":true},"outputs":[{"data":{"text/plain":["'\\nsns.lineplot(\\n        data=train_df,\\n        x=\"WEEK_NUM\",\\n        y=\"target\",\\n)\\nplt.show()\\n'"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["sns.lineplot(\n","        data=train_df,\n","        x=\"WEEK_NUM\",\n","        y=\"target\",\n",")\n","plt.show()\n"]},{"cell_type":"markdown","metadata":{},"source":["### Features - Missed values - Unique values"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T11:51:12.207113Z","iopub.status.busy":"2024-02-17T11:51:12.206887Z","iopub.status.idle":"2024-02-17T11:51:18.684211Z","shell.execute_reply":"2024-02-17T11:51:18.683450Z","shell.execute_reply.started":"2024-02-17T11:51:12.207093Z"},"trusted":true},"outputs":[],"source":["def dataframe_summary(dataframe):\n","    summary = dict()\n","    for col in dataframe.columns:\n","        missed_val = dataframe[col].isna().sum()\n","        summary[col] = {'missed': missed_val, \n","                        'missed_percentage': missed_val*100 / dataframe.shape[0], \n","                        'unique': dataframe[col].unique().__len__(),\n","                        'type': dataframe[col].dtype} \n","    return pd.DataFrame.from_dict(summary)\n","\n","train_df_summary = dataframe_summary(train_df).T\n","test_df_summary = dataframe_summary(test_df).T"]},{"cell_type":"markdown","metadata":{},"source":["### Now we have summary for our dataframes with:\n","* *missed*, missed values of the feature\n","* *missed_percentage*, percent of missed values in the column\n","* *unique*, number of unique values\n","* *type*, datatype of the feature"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T11:51:18.685450Z","iopub.status.busy":"2024-02-17T11:51:18.685185Z","iopub.status.idle":"2024-02-17T11:51:18.689356Z","shell.execute_reply":"2024-02-17T11:51:18.688476Z","shell.execute_reply.started":"2024-02-17T11:51:18.685428Z"},"trusted":true},"outputs":[],"source":["train_df_summary.T"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T11:51:18.690686Z","iopub.status.busy":"2024-02-17T11:51:18.690434Z","iopub.status.idle":"2024-02-17T11:51:18.699576Z","shell.execute_reply":"2024-02-17T11:51:18.698722Z","shell.execute_reply.started":"2024-02-17T11:51:18.690664Z"},"trusted":true},"outputs":[],"source":["train_df_summary[(train_df_summary.missed_percentage < 5) & (train_df_summary.type == 'category')].T"]},{"cell_type":"markdown","metadata":{},"source":["### Categorical features with large amount of unique values:\n","* lastapprcommoditycat_1041M - **45**\n","* lastcancelreason_561M - **74**\n","* lastrejectcommoditycat_161M - **45**\n","* lastrejectcommodtypec_5251769M - **187**"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T11:51:18.701001Z","iopub.status.busy":"2024-02-17T11:51:18.700712Z","iopub.status.idle":"2024-02-17T11:51:18.709249Z","shell.execute_reply":"2024-02-17T11:51:18.708489Z","shell.execute_reply.started":"2024-02-17T11:51:18.700980Z"},"trusted":true},"outputs":[],"source":["train_df.lastapprcommoditycat_1041M.unique()"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T11:51:18.710454Z","iopub.status.busy":"2024-02-17T11:51:18.710169Z","iopub.status.idle":"2024-02-17T11:51:18.719019Z","shell.execute_reply":"2024-02-17T11:51:18.718215Z","shell.execute_reply.started":"2024-02-17T11:51:18.710431Z"},"trusted":true},"outputs":[],"source":["train_df.lastcancelreason_561M.unique()"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T11:51:18.720937Z","iopub.status.busy":"2024-02-17T11:51:18.720082Z","iopub.status.idle":"2024-02-17T11:51:18.729123Z","shell.execute_reply":"2024-02-17T11:51:18.728155Z","shell.execute_reply.started":"2024-02-17T11:51:18.720907Z"},"trusted":true},"outputs":[],"source":["train_df.lastrejectcommoditycat_161M.unique()"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T11:51:18.731013Z","iopub.status.busy":"2024-02-17T11:51:18.730152Z","iopub.status.idle":"2024-02-17T11:51:18.738055Z","shell.execute_reply":"2024-02-17T11:51:18.737341Z","shell.execute_reply.started":"2024-02-17T11:51:18.730983Z"},"trusted":true},"outputs":[],"source":["train_df.lastrejectcommodtypec_5251769M.unique()"]},{"cell_type":"markdown","metadata":{},"source":["### Extra preprocessing:\n","* extract only features with 5% and less missed data\n","* replaced missed values with MEAN and MODE\n","* encode categorical data with less than 45 categories"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T11:51:18.739299Z","iopub.status.busy":"2024-02-17T11:51:18.739036Z","iopub.status.idle":"2024-02-17T11:52:19.794224Z","shell.execute_reply":"2024-02-17T11:52:19.793284Z","shell.execute_reply.started":"2024-02-17T11:51:18.739269Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Defining columns...\n"]},{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_34/2472453844.py:11: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n","  concat_df = pd.concat([train_dataframe, test_dataframe], ignore_index=True)\n","/tmp/ipykernel_34/2472453844.py:11: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n","  concat_df = pd.concat([train_dataframe, test_dataframe], ignore_index=True)\n","/tmp/ipykernel_34/2472453844.py:11: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n","  concat_df = pd.concat([train_dataframe, test_dataframe], ignore_index=True)\n","/tmp/ipykernel_34/2472453844.py:11: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n","  concat_df = pd.concat([train_dataframe, test_dataframe], ignore_index=True)\n","/tmp/ipykernel_34/2472453844.py:11: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n","  concat_df = pd.concat([train_dataframe, test_dataframe], ignore_index=True)\n","/tmp/ipykernel_34/2472453844.py:11: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n","  concat_df = pd.concat([train_dataframe, test_dataframe], ignore_index=True)\n","/tmp/ipykernel_34/2472453844.py:11: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n","  concat_df = pd.concat([train_dataframe, test_dataframe], ignore_index=True)\n","/tmp/ipykernel_34/2472453844.py:11: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n","  concat_df = pd.concat([train_dataframe, test_dataframe], ignore_index=True)\n","/tmp/ipykernel_34/2472453844.py:11: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n","  concat_df = pd.concat([train_dataframe, test_dataframe], ignore_index=True)\n","/tmp/ipykernel_34/2472453844.py:11: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n","  concat_df = pd.concat([train_dataframe, test_dataframe], ignore_index=True)\n","/tmp/ipykernel_34/2472453844.py:11: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n","  concat_df = pd.concat([train_dataframe, test_dataframe], ignore_index=True)\n","/tmp/ipykernel_34/2472453844.py:11: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n","  concat_df = pd.concat([train_dataframe, test_dataframe], ignore_index=True)\n","/tmp/ipykernel_34/2472453844.py:11: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n","  concat_df = pd.concat([train_dataframe, test_dataframe], ignore_index=True)\n","/tmp/ipykernel_34/2472453844.py:11: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n","  concat_df = pd.concat([train_dataframe, test_dataframe], ignore_index=True)\n","/tmp/ipykernel_34/2472453844.py:11: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n","  concat_df = pd.concat([train_dataframe, test_dataframe], ignore_index=True)\n","/tmp/ipykernel_34/2472453844.py:11: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n","  concat_df = pd.concat([train_dataframe, test_dataframe], ignore_index=True)\n"]},{"name":"stdout","output_type":"stream","text":["Fill missed numbers...\n","Fill missed categories...\n"]},{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_34/2472453844.py:19: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n","  concat_df[cat_feat] = concat_df[cat_feat].apply(lambda x: x.fillna(x.mode().iloc[0]),axis=0)\n"]},{"name":"stdout","output_type":"stream","text":["Encoding...\n","Done!\n"]}],"source":["def fillna_n_encode(train_dataframe, test_dataframe, summary):\n","    \n","    # define numeric and categorical columns with no more than 5% missed values\n","    print('Defining columns...')\n","    num_feat = summary[(summary.missed_percentage < 5) & (summary.type != 'category')].T.columns.to_list()\n","    num_feat.pop(2) # remove TARGET\n","    cat_feat = summary[(summary.missed_percentage < 5) & (summary.type == 'category') & (summary.unique < 45)].T.columns.to_list()\n","    \n","    # concat dataframes\n","    train_size = train_dataframe.shape[0]\n","    concat_df = pd.concat([train_dataframe, test_dataframe], ignore_index=True)\n","    \n","    # fill numeric missed values with mean value for the feature\n","    print('Fill missed numbers...')\n","    concat_df[num_feat] = concat_df[num_feat].apply(lambda x: x.fillna(x.mean()),axis=0)\n","\n","    # fill categorical missed values with mode value for the feature\n","    print('Fill missed categories...')\n","    concat_df[cat_feat] = concat_df[cat_feat].apply(lambda x: x.fillna(x.mode().iloc[0]),axis=0)\n","\n","    # redefine dataframe with only necesary columns\n","    concat_df = concat_df[num_feat + cat_feat + ['target']]\n","    \n","    # convert CATEGORY data with encoder\n","    print('Encoding...')\n","    ohe = OneHotEncoder(dtype=np.int8, drop='first')\n","    ohe.fit(concat_df[cat_feat])\n","    temp_df = pd.DataFrame(data=ohe.transform(concat_df[cat_feat]).toarray(), columns=ohe.get_feature_names_out())\n","    concat_df = pd.concat([concat_df.reset_index(drop=True), temp_df], axis=1)\n","    \n","    # drop columns\n","    concat_df.drop(cat_feat, axis=1, inplace=True)\n","    print('Done!')               \n","    return concat_df.iloc[:train_size], concat_df.iloc[train_size:] \n","    \n","train_df, test_df = fillna_n_encode(train_df, test_df, train_df_summary)\n","test_df = test_df.drop('target', axis=1)"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T11:52:19.795864Z","iopub.status.busy":"2024-02-17T11:52:19.795480Z","iopub.status.idle":"2024-02-17T11:52:19.801206Z","shell.execute_reply":"2024-02-17T11:52:19.800333Z","shell.execute_reply.started":"2024-02-17T11:52:19.795831Z"},"trusted":true},"outputs":[],"source":["del train_df_summary \n","del test_df_summary"]},{"cell_type":"markdown","metadata":{},"source":["# Modeling"]},{"cell_type":"markdown","metadata":{},"source":["## Feature importance"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T08:49:26.848121Z","iopub.status.busy":"2024-02-17T08:49:26.847807Z","iopub.status.idle":"2024-02-17T08:49:26.860962Z","shell.execute_reply":"2024-02-17T08:49:26.859650Z","shell.execute_reply.started":"2024-02-17T08:49:26.848098Z"},"trusted":true},"outputs":[],"source":["# TBD"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T11:52:19.802758Z","iopub.status.busy":"2024-02-17T11:52:19.802481Z","iopub.status.idle":"2024-02-17T11:52:19.812801Z","shell.execute_reply":"2024-02-17T11:52:19.811955Z","shell.execute_reply.started":"2024-02-17T11:52:19.802736Z"},"trusted":true},"outputs":[],"source":["drop_cols = []\n","# drop_cols_startwith = [\"std_\"]\n","# for name_prefix in drop_cols_startwith:\n","#     cols_names = train_df.columns[train_df.columns.str.startswith(name_prefix)]\n","#     drop_cols += cols_names.to_list()\n","# display(drop_cols)"]},{"cell_type":"markdown","metadata":{},"source":["## Define custom metric"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T11:52:19.814045Z","iopub.status.busy":"2024-02-17T11:52:19.813798Z","iopub.status.idle":"2024-02-17T11:52:19.827230Z","shell.execute_reply":"2024-02-17T11:52:19.826388Z","shell.execute_reply.started":"2024-02-17T11:52:19.814024Z"},"trusted":true},"outputs":[],"source":["def gini_stability(base, score_col=\"score\", w_fallingrate=88.0, w_resstd=-0.5):\n","    gini_in_time = base.loc[:, [\"WEEK_NUM\", \"target\", score_col]]\\\n","        .sort_values(\"WEEK_NUM\")\\\n","        .groupby(\"WEEK_NUM\")[[\"target\", score_col]]\\\n","        .apply(lambda x: 2*roc_auc_score(x[\"target\"], x[score_col])-1).tolist()\n","    \n","    x = np.arange(len(gini_in_time))\n","    y = gini_in_time\n","    a, b = np.polyfit(x, y, 1)\n","    y_hat = a*x + b\n","    residuals = y - y_hat\n","    res_std = np.std(residuals)\n","    avg_gini = np.mean(gini_in_time)\n","    return avg_gini + w_fallingrate * min(0, a) + w_resstd * res_std"]},{"cell_type":"markdown","metadata":{},"source":["## Test default models"]},{"cell_type":"code","execution_count":34,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T08:49:26.888000Z","iopub.status.busy":"2024-02-17T08:49:26.887639Z","iopub.status.idle":"2024-02-17T08:49:26.897796Z","shell.execute_reply":"2024-02-17T08:49:26.897004Z","shell.execute_reply.started":"2024-02-17T08:49:26.887967Z"},"trusted":true},"outputs":[],"source":["models = [\n","    #SVC(probability=True),\n","    LogisticRegression(max_iter=10000),\n","    KNeighborsClassifier(),\n","    RandomForestClassifier(),\n","    GradientBoostingClassifier(),\n","    HistGradientBoostingClassifier(),\n","    GaussianNB(),\n","    DecisionTreeClassifier(),\n","    xgb.XGBClassifier(),\n","    lgb.LGBMClassifier()\n","]\n"]},{"cell_type":"code","execution_count":35,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T08:49:26.899436Z","iopub.status.busy":"2024-02-17T08:49:26.898849Z","iopub.status.idle":"2024-02-17T09:05:05.224567Z","shell.execute_reply":"2024-02-17T09:05:05.223086Z","shell.execute_reply.started":"2024-02-17T08:49:26.899406Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["X shape:  (100000, 354)\n","#-------------------------------------------------------------------#\n","LogisticRegression\n","ROC AUC score: 0.6098035001557571\n","#-------------------------------------------------------------------#\n","KNeighborsClassifier\n","ROC AUC score: 0.5135698395514187\n","#-------------------------------------------------------------------#\n","RandomForestClassifier\n","ROC AUC score: 0.6832854076839169\n","#-------------------------------------------------------------------#\n","GradientBoostingClassifier\n","ROC AUC score: 0.7445007835270747\n","#-------------------------------------------------------------------#\n","HistGradientBoostingClassifier\n","ROC AUC score: 0.7383956147099674\n","#-------------------------------------------------------------------#\n","GaussianNB\n","ROC AUC score: 0.6212964548050978\n","#-------------------------------------------------------------------#\n","DecisionTreeClassifier\n","ROC AUC score: 0.515162060777212\n","#-------------------------------------------------------------------#\n","XGBClassifier\n","ROC AUC score: 0.7161658831137498\n","#-------------------------------------------------------------------#\n","LGBMClassifier\n","[LightGBM] [Info] Number of positive: 2461, number of negative: 77539\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.087116 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 5553\n","[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 219\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.030763 -> initscore=-3.450213\n","[LightGBM] [Info] Start training from score -3.450213\n","[LightGBM] [Info] Number of positive: 2461, number of negative: 77539\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.084112 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 5560\n","[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 220\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.030763 -> initscore=-3.450213\n","[LightGBM] [Info] Start training from score -3.450213\n","[LightGBM] [Info] Number of positive: 2461, number of negative: 77539\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.082585 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 5557\n","[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 220\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.030763 -> initscore=-3.450213\n","[LightGBM] [Info] Start training from score -3.450213\n","[LightGBM] [Info] Number of positive: 2461, number of negative: 77539\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.082785 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 5595\n","[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 219\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.030763 -> initscore=-3.450213\n","[LightGBM] [Info] Start training from score -3.450213\n","[LightGBM] [Info] Number of positive: 2460, number of negative: 77540\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.084318 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 5585\n","[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 219\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.030750 -> initscore=-3.450633\n","[LightGBM] [Info] Start training from score -3.450633\n","ROC AUC score: 0.7373580474525102\n"]}],"source":["train_df_100000 = train_df.sample(n=100000)\n","X = train_df_100000.drop(columns=[\"target\", \"case_id\", \"WEEK_NUM\"] + drop_cols)\n","print(\"X shape: \", X.shape)\n","y = train_df_100000[\"target\"]\n","weeks = train_df_100000[\"WEEK_NUM\"]\n","\n","results = dict()\n","\n","# look through models\n","for model in models:\n","\n","    print(\"#-------------------------------------------------------------------#\")\n","    print(type(model).__name__)\n","\n","    # calculate score\n","    res = (cross_val_score(model, X, y, cv=5, scoring=\"roc_auc\")).mean()\n","    print(f\"ROC AUC score: {res}\")\n","\n","    # record data\n","    results[type(model).__name__] = res\n"]},{"cell_type":"code","execution_count":37,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T09:43:16.445686Z","iopub.status.busy":"2024-02-17T09:43:16.445343Z","iopub.status.idle":"2024-02-17T09:43:16.457599Z","shell.execute_reply":"2024-02-17T09:43:16.456774Z","shell.execute_reply.started":"2024-02-17T09:43:16.445661Z"},"trusted":true},"outputs":[{"data":{"text/plain":["\"\\n 'LogisticRegression':             0.6098035001557571,\\n 'KNeighborsClassifier':           0.5135698395514187,\\n 'RandomForestClassifier':         0.6832854076839169,\\n 'GradientBoostingClassifier':     0.7445007835270747,\\n 'HistGradientBoostingClassifier': 0.7383956147099674,\\n 'GaussianNB':                     0.6212964548050978,\\n 'DecisionTreeClassifier':         0.515162060777212,\\n 'XGBClassifier':                  0.7161658831137498,\\n 'LGBMClassifier':                 0.7373580474525102}\\n\""]},"execution_count":37,"metadata":{},"output_type":"execute_result"}],"source":["'''\n"," 'LogisticRegression':             0.6098035001557571,\n"," 'KNeighborsClassifier':           0.5135698395514187,\n"," 'RandomForestClassifier':         0.6832854076839169,\n"," 'GradientBoostingClassifier':     0.7445007835270747,\n"," 'HistGradientBoostingClassifier': 0.7383956147099674,\n"," 'GaussianNB':                     0.6212964548050978,\n"," 'DecisionTreeClassifier':         0.515162060777212,\n"," 'XGBClassifier':                  0.7161658831137498,\n"," 'LGBMClassifier':                 0.7373580474525102}\n","'''"]},{"cell_type":"markdown","metadata":{},"source":["## LGBM \n","(best: )"]},{"cell_type":"code","execution_count":36,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T12:33:41.091352Z","iopub.status.busy":"2024-02-17T12:33:41.090600Z","iopub.status.idle":"2024-02-17T12:36:01.251562Z","shell.execute_reply":"2024-02-17T12:36:01.250288Z","shell.execute_reply.started":"2024-02-17T12:33:41.091321Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["X shape:  (1526659, 305)\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/lightgbm/callback.py:325: UserWarning: Early stopping is not available in dart mode\n","  _log_warning('Early stopping is not available in dart mode')\n"]},{"name":"stdout","output_type":"stream","text":["[100]\tvalid_0's auc: 0.689746\n","[200]\tvalid_0's auc: 0.694182\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[36], line 40\u001b[0m\n\u001b[1;32m     37\u001b[0m X_valid, y_valid \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39miloc[idx_valid], y\u001b[38;5;241m.\u001b[39miloc[idx_valid]\n\u001b[1;32m     39\u001b[0m model \u001b[38;5;241m=\u001b[39m lgb\u001b[38;5;241m.\u001b[39mLGBMClassifier(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m---> 40\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_valid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_valid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mlgb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_evaluation\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlgb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mearly_stopping\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m fitted_models\u001b[38;5;241m.\u001b[39mappend(model)\n\u001b[1;32m     46\u001b[0m val_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict_proba(X_valid)[:, \u001b[38;5;241m1\u001b[39m]\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/lightgbm/sklearn.py:1187\u001b[0m, in \u001b[0;36mLGBMClassifier.fit\u001b[0;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m   1184\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1185\u001b[0m             valid_sets\u001b[38;5;241m.\u001b[39mappend((valid_x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_le\u001b[38;5;241m.\u001b[39mtransform(valid_y)))\n\u001b[0;32m-> 1187\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1188\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1189\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1190\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1192\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_sets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1193\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1194\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_sample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_class_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_class_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1196\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_init_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_init_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1197\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_metric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcategorical_feature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcategorical_feature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1200\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1201\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_model\u001b[49m\n\u001b[1;32m   1202\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1203\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/lightgbm/sklearn.py:885\u001b[0m, in \u001b[0;36mLGBMModel.fit\u001b[0;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m    882\u001b[0m evals_result: _EvalResultDict \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    883\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mappend(record_evaluation(evals_result))\n\u001b[0;32m--> 885\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    887\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_estimators\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    889\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_sets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_sets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    891\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_metrics_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m    892\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    893\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    894\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\n\u001b[1;32m    895\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    897\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_evals_result \u001b[38;5;241m=\u001b[39m evals_result\n\u001b[1;32m    898\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_best_iteration \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster\u001b[38;5;241m.\u001b[39mbest_iteration\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/lightgbm/engine.py:276\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, feval, init_model, feature_name, categorical_feature, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cb \u001b[38;5;129;01min\u001b[39;00m callbacks_before_iter:\n\u001b[1;32m    269\u001b[0m     cb(callback\u001b[38;5;241m.\u001b[39mCallbackEnv(model\u001b[38;5;241m=\u001b[39mbooster,\n\u001b[1;32m    270\u001b[0m                             params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[1;32m    271\u001b[0m                             iteration\u001b[38;5;241m=\u001b[39mi,\n\u001b[1;32m    272\u001b[0m                             begin_iteration\u001b[38;5;241m=\u001b[39minit_iteration,\n\u001b[1;32m    273\u001b[0m                             end_iteration\u001b[38;5;241m=\u001b[39minit_iteration \u001b[38;5;241m+\u001b[39m num_boost_round,\n\u001b[1;32m    274\u001b[0m                             evaluation_result_list\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m--> 276\u001b[0m \u001b[43mbooster\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    278\u001b[0m evaluation_result_list: List[_LGBM_BoosterEvalMethodResultType] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    279\u001b[0m \u001b[38;5;66;03m# check evaluation result.\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/lightgbm/basic.py:3891\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   3889\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__set_objective_to_none:\n\u001b[1;32m   3890\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LightGBMError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCannot update due to null objective function.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 3891\u001b[0m _safe_call(\u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLGBM_BoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3892\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3893\u001b[0m \u001b[43m    \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mis_finished\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   3894\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__is_predicted_cur_iter \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__num_dataset)]\n\u001b[1;32m   3895\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m is_finished\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["X = train_df.drop(columns=[\"target\", \"case_id\", \"WEEK_NUM\"] + drop_cols)\n","print(\"X shape: \", X.shape)\n","y = train_df[\"target\"]\n","weeks = train_df[\"WEEK_NUM\"]\n","\n","cv = StratifiedGroupKFold(n_splits=5, shuffle=False)\n","\"\"\"\n","params = {\n","    \"boosting_type\": \"gbdt\",\n","    \"objective\": \"binary\",\n","    \"metric\": \"auc\",\n","    \"max_depth\": 8,\n","    \"max_bin\": 255,\n","    \"learning_rate\": 0.05,\n","    \"n_estimators\": 1000,\n","    \"colsample_bytree\": 0.8, \n","    \"colsample_bynode\": 0.8,\n","    \"verbose\": -1,\n","    \"random_state\": 42,\n","    \"device\": \"gpu\",\n","}\n","\"\"\"\n","# params after tuning\n","params = {'num_leaves': 34, 'max_depth': 3, 'learning_rate': 0.03932342591510133, 'n_estimators': 293, 'max_bin': 32, 'boosting': 'dart', 'tree_learner': 'voting',\n","    \"verbose\": -1,\n","    \"random_state\": 42,\n","    \"device\": \"gpu\",\n","    \"metric\": \"auc\",}\n","\n","\n","fitted_models = []\n","oof_pred = np.zeros(X.shape[0])\n","\n","for idx_train, idx_valid in cv.split(X, y, groups=weeks):\n","    X_train, y_train = X.iloc[idx_train], y.iloc[idx_train]\n","    X_valid, y_valid = X.iloc[idx_valid], y.iloc[idx_valid]\n","\n","    model = lgb.LGBMClassifier(**params)\n","    model.fit(\n","        X_train, y_train,\n","        eval_set=[(X_valid, y_valid)],\n","        callbacks=[lgb.log_evaluation(100), lgb.early_stopping(100)]\n","    )\n","    fitted_models.append(model)\n","    val_pred = model.predict_proba(X_valid)[:, 1]\n","    oof_pred[idx_valid] = val_pred\n","    gc.collect()\n","#'''"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-14T15:07:49.109481Z","iopub.status.busy":"2024-02-14T15:07:49.109086Z","iopub.status.idle":"2024-02-14T15:07:49.808587Z","shell.execute_reply":"2024-02-14T15:07:49.807586Z","shell.execute_reply.started":"2024-02-14T15:07:49.109453Z"},"trusted":true},"outputs":[],"source":["roc_auc_oof = roc_auc_score(y, oof_pred)\n","print(\"CV roc_auc_oof: \", roc_auc_oof)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-14T15:07:51.633162Z","iopub.status.busy":"2024-02-14T15:07:51.632763Z","iopub.status.idle":"2024-02-14T15:07:52.434408Z","shell.execute_reply":"2024-02-14T15:07:52.433471Z","shell.execute_reply.started":"2024-02-14T15:07:51.633133Z"},"trusted":true},"outputs":[],"source":["oof_df = train_df[[\"WEEK_NUM\", \"target\"]].copy()\n","oof_df[\"pred_oof\"] = oof_pred\n","gini_score = gini_stability(oof_df, score_col=\"pred_oof\")\n","print(\"gini_score:\\t\", gini_score)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-14T15:07:56.407889Z","iopub.status.busy":"2024-02-14T15:07:56.407045Z","iopub.status.idle":"2024-02-14T15:07:56.457780Z","shell.execute_reply":"2024-02-14T15:07:56.456844Z","shell.execute_reply.started":"2024-02-14T15:07:56.407838Z"},"trusted":true},"outputs":[],"source":["oof_models_dict = [(str(i), model) for i, model in enumerate(fitted_models)]\n","\n","model = VotingClassifier(\n","    estimators=oof_models_dict,\n","    voting='soft',\n",")\n","model.estimators_ = fitted_models\n","model.le_ = LabelEncoder().fit(y)\n","model.classes_ = model.le_.classes_\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-14T14:36:52.859438Z","iopub.status.busy":"2024-02-14T14:36:52.859111Z","iopub.status.idle":"2024-02-14T14:36:52.867133Z","shell.execute_reply":"2024-02-14T14:36:52.866289Z","shell.execute_reply.started":"2024-02-14T14:36:52.859408Z"},"trusted":true},"outputs":[],"source":["joblib.dump(model, \"oof_model_1.pkl\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-14T14:36:52.868481Z","iopub.status.busy":"2024-02-14T14:36:52.868200Z","iopub.status.idle":"2024-02-14T14:36:52.876470Z","shell.execute_reply":"2024-02-14T14:36:52.875728Z","shell.execute_reply.started":"2024-02-14T14:36:52.868446Z"},"trusted":true},"outputs":[],"source":["joblib.dump((train_df.columns, cat_cols, drop_cols), \"train_cat_columns.pkl\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-14T14:36:52.877844Z","iopub.status.busy":"2024-02-14T14:36:52.877515Z","iopub.status.idle":"2024-02-14T14:36:52.886523Z","shell.execute_reply":"2024-02-14T14:36:52.885613Z","shell.execute_reply.started":"2024-02-14T14:36:52.877810Z"},"trusted":true},"outputs":[],"source":["joblib.dump(oof_pred, \"oof_pred.pkl\")"]},{"cell_type":"markdown","metadata":{},"source":["## XGBooster (mostly show worse results)\n","(best: )"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-14T14:49:42.554223Z","iopub.status.busy":"2024-02-14T14:49:42.553493Z","iopub.status.idle":"2024-02-14T14:51:04.855983Z","shell.execute_reply":"2024-02-14T14:51:04.855148Z","shell.execute_reply.started":"2024-02-14T14:49:42.554185Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["X = train_df.drop(columns=[\"target\", \"case_id\", \"WEEK_NUM\"] + drop_cols)\n","print(\"X shape: \", X.shape)\n","y = train_df[\"target\"]\n","weeks = train_df[\"WEEK_NUM\"]\n","\n","cv = StratifiedGroupKFold(n_splits=5, shuffle=False)\n","\n","params = {\n","    \"booster\": \"dart\", #  gbtee\n","    \"objective\": \"binary:logistic\",\n","    \"eval_metric\": \"auc\",\n","    \"max_depth\": 8,\n","    \"max_bin\": 255,\n","    \"learning_rate\": 0.05,\n","    #\"n_estimators\": 1000,\n","    #\"verbose\": -1,\n","    \"random_state\": 42,\n","    \"device\": \"gpu\",\n","}\n","\n","fitted_models = []\n","oof_pred = np.zeros(X.shape[0])\n","\n","early_stop = xgb.callback.EarlyStopping(rounds=100,\n","                                        metric_name='auc',\n","                                        data_name='Valid')\n","\n","for idx_train, idx_valid in cv.split(X, y, groups=weeks):\n","\n","    D_train = xgb.DMatrix(X.iloc[idx_train], y.iloc[idx_train])\n","    D_valid = xgb.DMatrix(X.iloc[idx_valid], y.iloc[idx_valid])\n","\n","    model = xgb.train(\n","        {**params},\n","        D_train,\n","        evals=[(D_train, 'Train'), (D_valid, 'Valid')],\n","        verbose_eval=100,\n","        callbacks=[early_stop]        \n","    )\n","    fitted_models.append(model)\n","    val_pred = model.predict(D_valid)\n","    oof_pred[idx_valid] = val_pred\n","    gc.collect()\n","    \n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-14T14:55:34.335163Z","iopub.status.busy":"2024-02-14T14:55:34.334124Z","iopub.status.idle":"2024-02-14T14:55:34.967629Z","shell.execute_reply":"2024-02-14T14:55:34.966540Z","shell.execute_reply.started":"2024-02-14T14:55:34.335133Z"},"trusted":true},"outputs":[],"source":["roc_auc_oof = roc_auc_score(y, oof_pred)\n","print(\"CV roc_auc_oof: \", roc_auc_oof)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-14T14:55:41.340589Z","iopub.status.busy":"2024-02-14T14:55:41.340232Z","iopub.status.idle":"2024-02-14T14:55:42.083149Z","shell.execute_reply":"2024-02-14T14:55:42.082134Z","shell.execute_reply.started":"2024-02-14T14:55:41.340559Z"},"trusted":true},"outputs":[],"source":["oof_df = train_df[[\"WEEK_NUM\", \"target\"]].copy()\n","oof_df[\"pred_oof\"] = oof_pred\n","gini_score = gini_stability(oof_df, score_col=\"pred_oof\")\n","print(\"gini_score:\\t\", gini_score)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-14T14:55:47.160469Z","iopub.status.busy":"2024-02-14T14:55:47.159768Z","iopub.status.idle":"2024-02-14T14:55:47.204874Z","shell.execute_reply":"2024-02-14T14:55:47.203853Z","shell.execute_reply.started":"2024-02-14T14:55:47.160436Z"},"trusted":true},"outputs":[],"source":["oof_models_dict = [(str(i), model) for i, model in enumerate(fitted_models)]\n","\n","model = VotingClassifier(\n","    estimators=oof_models_dict,\n","    voting='soft',\n",")\n","model.estimators_ = fitted_models\n","model.le_ = LabelEncoder().fit(y)\n","model.classes_ = model.le_.classes_"]},{"cell_type":"markdown","metadata":{},"source":["# Hypertuning"]},{"cell_type":"markdown","metadata":{},"source":["### Grad Booster\n","(best: )"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T11:29:30.799120Z","iopub.status.busy":"2024-02-17T11:29:30.798602Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["[I 2024-02-17 11:29:32,051] A new study created in memory with name: no-name-82961765-5356-404c-b95d-6296b145f1cb\n"]},{"name":"stdout","output_type":"stream","text":["X shape:  (10000, 354)\n"]},{"name":"stderr","output_type":"stream","text":["[I 2024-02-17 11:29:34,896] Trial 0 finished with value: 0.650293508752236 and parameters: {'loss': 'exponential', 'n_estimators': 99, 'max_depth': 85, 'learning_rate': 0.5129796947676725, 'min_samples_leaf': 32, 'max_features': 'log2', 'min_samples_split': 14, 'criterion': 'friedman_mse'}. Best is trial 0 with value: 0.650293508752236.\n","[I 2024-02-17 11:29:38,552] Trial 1 finished with value: 0.7082544529813631 and parameters: {'loss': 'log_loss', 'n_estimators': 365, 'max_depth': 4, 'learning_rate': 0.016142105051264524, 'min_samples_leaf': 25, 'max_features': 'log2', 'min_samples_split': 8, 'criterion': 'friedman_mse'}. Best is trial 1 with value: 0.7082544529813631.\n","[I 2024-02-17 11:32:47,067] Trial 2 finished with value: 0.6796333309142266 and parameters: {'loss': 'exponential', 'n_estimators': 198, 'max_depth': 33, 'learning_rate': 0.02643708435056029, 'min_samples_leaf': 12, 'max_features': None, 'min_samples_split': 2, 'criterion': 'friedman_mse'}. Best is trial 1 with value: 0.7082544529813631.\n","[I 2024-02-17 11:32:58,599] Trial 3 finished with value: 0.6323036707373536 and parameters: {'loss': 'exponential', 'n_estimators': 616, 'max_depth': 8, 'learning_rate': 0.08073915113743702, 'min_samples_leaf': 17, 'max_features': 'log2', 'min_samples_split': 48, 'criterion': 'squared_error'}. Best is trial 1 with value: 0.7082544529813631.\n","[I 2024-02-17 11:40:59,806] Trial 4 finished with value: 0.6370907818082295 and parameters: {'loss': 'log_loss', 'n_estimators': 365, 'max_depth': 32, 'learning_rate': 0.055565234735707236, 'min_samples_leaf': 4, 'max_features': None, 'min_samples_split': 22, 'criterion': 'squared_error'}. Best is trial 1 with value: 0.7082544529813631.\n"]}],"source":["\n","train_df_subsample = train_df.sample(n=10000)\n","X = train_df_subsample.drop(columns=[\"target\", \"case_id\", \"WEEK_NUM\"] + drop_cols)\n","print(\"X shape: \", X.shape)\n","y = train_df_subsample[\"target\"]\n","weeks = train_df_subsample[\"WEEK_NUM\"]\n","\n","def objective(trial):\n","    \"\"\"Define the objective function\"\"\"\n","\n","    params = {\n","        'loss': trial.suggest_categorical('loss', [\"log_loss\", \"exponential\"]),\n","        'n_estimators': trial.suggest_int('n_estimators', 10, 1000),\n","        'max_depth': trial.suggest_int('max_depth', 1, 100),\n","        'learning_rate': trial.suggest_float('learning_rate', 0.01, 1.0, log=True),\n","        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 50),\n","        'max_features': trial.suggest_categorical('max_features', [\"sqrt\", \"log2\", None]),\n","        'min_samples_split': trial.suggest_int('min_samples_split', 2, 50),\n","        'criterion': trial.suggest_categorical('criterion', [\"friedman_mse\", \"squared_error\"]),\n","        }\n","\n","    # Fit the model\n","    optuna_model = GradientBoostingClassifier(**params)\n","    scores = cross_val_score(optuna_model, X, y, cv=3, scoring=\"roc_auc\")\n","    score = scores.mean()\n","    return score\n","\n","\n","study = optuna.create_study(direction='maximize')\n","study.optimize(objective, n_trials=30)\n","\n","print('Number of finished trials: {}'.format(len(study.trials)))\n","print('Best trial:')\n","trial = study.best_trial\n","\n","print('  Value: {}'.format(trial.value))\n","print('  Params: ')\n","\n","for key, value in trial.params.items():\n","    print('    {}: {}'.format(key, value))"]},{"cell_type":"markdown","metadata":{},"source":["### LGBM\n","(best: 0.6732)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T12:38:05.026725Z","iopub.status.busy":"2024-02-17T12:38:05.025588Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["[I 2024-02-17 12:38:05,139] A new study created in memory with name: no-name-adecbc94-6b05-4e56-8659-469ee3255662\n"]},{"name":"stdout","output_type":"stream","text":["X shape:  (10000, 305)\n"]}],"source":["train_df_subsample = train_df.sample(n=10000)\n","X = train_df_subsample.drop(columns=[\"target\", \"case_id\", \"WEEK_NUM\"] + drop_cols)\n","print(\"X shape: \", X.shape)\n","y = train_df_subsample[\"target\"]\n","weeks = train_df_subsample[\"WEEK_NUM\"]\n","\n","def objective(trial):\n","    \"\"\"Define the objective function\"\"\"\n","\n","    params = {\n","        'num_leaves': trial.suggest_int('num_leaves', 2, 100),\n","        'max_depth': trial.suggest_int('max_depth', 1, 100),\n","        'learning_rate': trial.suggest_float('learning_rate', 0.01, 1.0, log=True),\n","        'n_estimators': trial.suggest_int('n_estimators', 10, 2000),\n","        'max_bin': trial.suggest_int('max_bin', 1, 255),\n","        'boosting': trial.suggest_categorical('boosting', ['gbdt', 'dart']),\n","        'objective': 'binary',\n","        'tree_learner': trial.suggest_categorical('tree_learner', ['serial', 'feature', 'data', 'voting']),\n","\n","        \"metric\": 'auc',\n","        \"verbosity\": -1,\n","        \"device\": \"gpu\",\n","        \"objective\": \"binary\",\n","    }\n","\n","    # Fit the model\n","    optuna_model = lgb.LGBMClassifier(**params)\n","    scores = cross_val_score(optuna_model, X, y, cv=3, scoring=\"roc_auc\")\n","    score = scores.mean()\n","    return score\n","\n","\n","study = optuna.create_study(direction='maximize')\n","study.optimize(objective, n_trials=100)\n","\n","print('Number of finished trials: {}'.format(len(study.trials)))\n","print('Best trial:')\n","trial = study.best_trial\n","\n","print('  Value: {}'.format(trial.value))\n","print('  Params: ')\n","\n","for key, value in trial.params.items():\n","    print('    {}: {}'.format(key, value))"]},{"cell_type":"markdown","metadata":{},"source":["# Results"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-02-14T14:36:53.562413Z","iopub.status.idle":"2024-02-14T14:36:53.562753Z","shell.execute_reply":"2024-02-14T14:36:53.562598Z","shell.execute_reply.started":"2024-02-14T14:36:53.562584Z"},"trusted":true},"outputs":[],"source":["# TBD"]},{"cell_type":"markdown","metadata":{},"source":["# Prediction"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-14T15:08:21.187817Z","iopub.status.busy":"2024-02-14T15:08:21.187453Z","iopub.status.idle":"2024-02-14T15:08:21.194860Z","shell.execute_reply":"2024-02-14T15:08:21.193677Z","shell.execute_reply.started":"2024-02-14T15:08:21.187778Z"},"trusted":true},"outputs":[],"source":["def predict_proba_in_batches(model, data, batch_size=100000):\n","    num_samples = len(data)\n","    num_batches = int(np.ceil(num_samples / batch_size))\n","    probabilities = np.zeros((num_samples,))\n","\n","    for batch_idx in range(num_batches):\n","        print(f\"Processing batch: {batch_idx+1}/{num_batches}\")\n","        start_idx = batch_idx * batch_size\n","        end_idx = min((batch_idx + 1) * batch_size, num_samples)\n","        X_batch = data.iloc[start_idx:end_idx]\n","        batch_probs = model.predict_proba(X_batch)[:, 1]\n","        probabilities[start_idx:end_idx] = batch_probs\n","        gc.collect()\n","\n","    return probabilities"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-14T15:08:22.474346Z","iopub.status.busy":"2024-02-14T15:08:22.473507Z","iopub.status.idle":"2024-02-14T15:08:22.666175Z","shell.execute_reply":"2024-02-14T15:08:22.665265Z","shell.execute_reply.started":"2024-02-14T15:08:22.474316Z"},"trusted":true},"outputs":[],"source":["X_test = test_df.drop(columns=[\"WEEK_NUM\"] + drop_cols)\n","X_test = X_test.set_index(\"case_id\")\n","print(\"X_test shape: \", X_test.shape)\n","\n","y_pred = pd.Series(predict_proba_in_batches(model, X_test), index=X_test.index)\n","y_pred[:10]"]},{"cell_type":"markdown","metadata":{},"source":["# Submit"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-14T15:08:36.269951Z","iopub.status.busy":"2024-02-14T15:08:36.269557Z","iopub.status.idle":"2024-02-14T15:08:36.280201Z","shell.execute_reply":"2024-02-14T15:08:36.279083Z","shell.execute_reply.started":"2024-02-14T15:08:36.269918Z"},"trusted":true},"outputs":[],"source":["subm_df = pd.read_csv(CFG.root_dir / \"sample_submission.csv\")\n","subm_df = subm_df.set_index(\"case_id\")\n","\n","subm_df[\"score\"] = y_pred"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-14T15:08:42.687847Z","iopub.status.busy":"2024-02-14T15:08:42.687093Z","iopub.status.idle":"2024-02-14T15:08:42.697701Z","shell.execute_reply":"2024-02-14T15:08:42.696783Z","shell.execute_reply.started":"2024-02-14T15:08:42.687791Z"},"trusted":true},"outputs":[],"source":["print(\"Check null: \", subm_df[\"score\"].isnull().any())\n","\n","subm_df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-14T15:10:18.267670Z","iopub.status.busy":"2024-02-14T15:10:18.266962Z","iopub.status.idle":"2024-02-14T15:10:18.273293Z","shell.execute_reply":"2024-02-14T15:10:18.272258Z","shell.execute_reply.started":"2024-02-14T15:10:18.267641Z"},"trusted":true},"outputs":[],"source":["subm_df.to_csv(\"submission.csv\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"databundleVersionId":7602123,"sourceId":50160,"sourceType":"competition"}],"dockerImageVersionId":30646,"isGpuEnabled":true,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
